{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418181e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë­ì²´ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤...\n",
      "1ë²ˆì§¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...\n",
      "2ë²ˆì§¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...\n",
      "3ë²ˆì§¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...\n",
      "4ë²ˆì§¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...\n",
      "5ë²ˆì§¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...\n",
      "6ë²ˆì§¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...\n",
      "7ë²ˆì§¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...\n",
      "âœ…ë‹µë³€ ìƒì„± ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "import os \n",
    "import json\n",
    "import datetime\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import io\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from io import BytesIO\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Image as ReportImage, Spacer\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.lib import colors\n",
    "from reportlab.pdfbase import pdfmetrics\n",
    "from reportlab.pdfbase.ttfonts import TTFont\n",
    "from reportlab.platypus import PageBreak\n",
    "\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ë“±ë¡\n",
    "# Windowsì— ì„¤ì¹˜ëœ ê¸°ë³¸ í•œê¸€ í°íŠ¸ ì‚¬ìš©\n",
    "pdfmetrics.registerFont(TTFont('Malgun', 'C:/Windows/Fonts/malgun.ttf'))\n",
    "pdfmetrics.registerFont(TTFont('MalgunBold', 'C:/Windows/Fonts/malgunbd.ttf'))\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# API KEY ì •ë³´ë¡œë“œ\n",
    "API_KEY = os.getenv(\"OPEN_API_KEY\")\n",
    "\n",
    "video_name = \"bb_1_220122_vehicle_229_34825\"\n",
    "\n",
    "work_dir = \"C:/Users/Noh/github/Accident_Prediction_Prevent/Models/work_dir/\"\n",
    "\n",
    "pdf_path = work_dir + \"LangChain/pdf_data/231107_ê³¼ì‹¤ë¹„ìœ¨ì¸ì •ê¸°ì¤€_ì˜¨ë¼ì¸ìš©.pdf\"\n",
    "json_path = work_dir + \"datasets/results/\" + video_name + \"_classification.json\"\n",
    "\n",
    "output_dir = work_dir + \"/datasets/results/\"\n",
    "\n",
    "### ì‚¬ê³  ì •ë³´ ë§¤í•‘ íŒŒì¼ ë¡œë“œ\n",
    "def load_mapping_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        return json.load(file)\n",
    "    \n",
    "json_file = load_mapping_file(json_path) # ëª¨ë¸ ì•„ì›ƒí’‹ íŒŒì¼\n",
    "\n",
    "one = json_file[0][\"accident_place\"]\n",
    "two = json_file[0][\"accident_place_feature\"]\n",
    "three = json_file[0][\"object_A\"]\n",
    "four = json_file[0][\"object_B\"]\n",
    "\n",
    "### ë­ì²´ì¸ ì‹¤í–‰\n",
    "print(\"ë­ì²´ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤...\")\n",
    "# ë‹¨ê³„ 1 : ë¬¸ì„œ ë¡œë“œ\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "docs = loader.load()\n",
    "\n",
    "# ë‹¨ê³„ 2 : ë¬¸ì„œ ë¶„í• \n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    ")\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# ë‹¨ê³„ 3 : ì„ë² ë”©\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"  # ë” ê°€ë²¼ìš´ ëª¨ë¸\n",
    ")\n",
    "\n",
    "# ë‹¨ê³„ 4 : ë²¡í„° ìŠ¤í† ì–´ ìƒì„±\n",
    "vectorstore = FAISS.from_documents(split_documents, embeddings)\n",
    "\n",
    "# ë‹¨ê³„ 5 : ê²€ìƒ‰ê¸° ìƒì„±\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# ë‹¨ê³„ 6 : í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    ë‹¹ì‹ ì€ êµí†µì‚¬ê³  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "    ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¡œ ì‚¬ê³  ì •ë³´ë¥¼ ì •ë¦¬í•´ì£¼ì„¸ìš”.\n",
    "    ~~ ì…ë‹ˆë‹¤. ~~ ë‹µë³€ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ë“±ì˜ ë‹µë³€ì€ í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "\n",
    "    ì‚¬ê³ ìœ í˜•ë²ˆí˜¸ì— ëŒ€í•´ ë¬¼ì–´ë³´ë©´ ì˜ˆì‹œì™€ ë™ì¼í•œ ìœ í˜•ì˜ ì‚¬ê³ ìœ í˜• ë²ˆí˜¸ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”. ì—†ìœ¼ë©´ ë‹µí•˜ì§€ ë§ˆì„¸ìš”. (ì˜ˆì‹œ : ì°¨15-1, ë³´9 ë“±)\n",
    "\n",
    "    ì‚¬ê±´ì •ë³´ì— ëŒ€í•´ ë¬¼ì–´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. :\n",
    "    [ì‚¬ê±´ë¶„ë¥˜: (ì˜ˆ: ì°¨ëŒ€ ë³´í–‰ì / ì°¨ëŒ€ ì´ë¥œì°¨ / ì°¨ëŒ€ ìì „ê±° / ì°¨ëŒ€ì°¨)\n",
    "    ì‚¬ê³ ì¥ì†Œ: (ë„ë¡œ í˜•íƒœ ë˜ëŠ” ì‚¬ê³  ë°œìƒ ì§€ì  ìš”ì•½)\n",
    "    ê°ì²´ A ìƒíƒœ: (í–‰ë™/ìœ„ì¹˜/ì‹ í˜¸ ìƒíƒœ ë“±)\n",
    "    ê°ì²´ B ìƒíƒœ: (í–‰ë™/ìœ„ì¹˜/ì‹ í˜¸ ìƒíƒœ ë“±)\n",
    "\n",
    "    ì‚¬ê³  ìƒí™©: (êµ¬ì²´ì ìœ¼ë¡œ ì„œìˆ í•´ì£¼ì„¸ìš”. ì˜ˆ: ì‹ í˜¸ë“±ì´ ìˆëŠ” êµì°¨ë¡œì—ì„œ ë³´í–‰ìê°€ ì‹ í˜¸ë¥¼ ë¬´ì‹œí•˜ê³  íš¡ë‹¨ë³´ë„ë¥¼ ê±´ë„ˆëŠ” ìƒí™©)]\n",
    "\n",
    "    ê¸°ë³¸ ê³¼ì‹¤ë¹„ìœ¨ì— ëŒ€í•´ ë¬¼ì–´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. :\n",
    "    [ê¸°ë³¸ ê³¼ì‹¤ë¹„ìœ¨ : (ì˜ˆ: A50:B50 / A70:B30)]\n",
    "\n",
    "    ê³¼ì‹¤ ë¹„ìœ¨ ì¡°ì • ìš”ì†Œì— ëŒ€í•´ ë¬¼ì–´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. :\n",
    "    ì‚¬ê³  ë°œìƒì— ë”°ë¼ ì ìš© ê°€ëŠ¥í•œ ê°€ê° ìš”ì†Œë¥¼ ì •ë¦¬í•´ì£¼ê³ , ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” í•­ëª©ê³¼ ìˆ˜ì¹˜ë§Œì„ êµ¬ì²´ì ìœ¼ë¡œ ì ì–´ì£¼ì„¸ìš”.\n",
    "\n",
    "    ê´€ë ¨ ë²•ë¥ ì— ëŒ€í•´ ë¬¼ì–´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. :\n",
    "    [ê´€ë ¨ ë²•ë¥  : (ì˜ˆ: ë„ë¡œêµí†µë²• ì œ5ì¡° (ì‹ í˜¸ ë˜ëŠ” ì§€ì‹œì— ë”°ë¥¼ ì˜ë¬´))]\n",
    "\n",
    "    ì°¸ê³  íŒë¡€ì— ëŒ€í•´ ë¬¼ì–´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. :\n",
    "    - ë²•ì›ëª… : \n",
    "    - ì„ ê³ ì¼ :\n",
    "    - ì‚¬ê±´ë²ˆí˜¸\n",
    "    - í•µì‹¬ ë‚´ìš© ìš”ì•½\n",
    "    - ê³¼ì‹¤ë¹„ìœ¨ ìš”ì•½ (ìˆë‹¤ë©´)\n",
    "\n",
    "    ì‚¬ê³  ìš”ì•½ì— ëŒ€í•´ ë¬¼ì–´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. :\n",
    "    [ì‚¬ê³  ìš”ì•½ : (ì‚¬ê³  ìœ í˜•, ì¥ì†Œ, ê°ì²´ Aì™€ Bì˜ ìƒíƒœ)]\n",
    "\n",
    "    ì§ˆë¬¸:\n",
    "    {question}\n",
    "\n",
    "    ì°¸ê³  ë¬¸ì„œ:\n",
    "    {context}\n",
    "\n",
    "    ìœ„ í˜•ì‹ì„ ì •í™•íˆ ë”°ë¥´ê³ , í•œêµ­ì–´ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# ë‹¨ê³„ 7: ì–¸ì–´ëª¨ë¸(LLM) ìƒì„±\n",
    "# ëª¨ë¸(LLM) ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\",\n",
    "                openai_api_key=API_KEY,\n",
    "                temperature=0)\n",
    "\n",
    "# ë‹¨ê³„ 8: ì²´ì¸(Chain) ìƒì„±\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "accident = f\"ì‚¬ê³  ì¥ì†Œ {one} ì‚¬ê³  ìœ í˜• {two} ì‚¬ê³  ê°ì²´ Aì˜ ì§„í–‰ ë°©í–¥ {three} ì‚¬ê³  ê°ì²´ Bì˜ ì§„í–‰ ë°©í–¥ {four}ì— í•´ë‹¹í•˜ëŠ” ì‚¬ê³ \"\n",
    "\n",
    "questions = [accident + \"ì˜ ì‚¬ê³ ìœ í˜•ë²ˆí˜¸ëŠ”?\",\n",
    "            accident + \"ì˜ ì‚¬ê±´ì •ë³´ëŠ”?\",\n",
    "            accident + \"ì˜ ê¸°ë³¸ ê³¼ì‹¤ ë¹„ìœ¨ì€?\",\n",
    "            accident + \"ì˜ ê³¼ì‹¤ ë¹„ìœ¨ ì¡°ì • ìš”ì†ŒëŠ”?\",\n",
    "            accident + \"ì˜ ê´€ë ¨ ë²•ë¥ ì€?\",\n",
    "            accident + \"ì˜ ì°¸ê³  íŒë¡€ëŠ”?\",\n",
    "            accident + \"ìš”ì•½ ì •ë¦¬\"\n",
    "            ]\n",
    "\n",
    "res = []\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰(Run Chain)\n",
    "# ë¬¸ì„œì— ëŒ€í•œ ì§ˆì˜ë¥¼ ì…ë ¥í•˜ê³ , ë‹µë³€ê³¼ ê´€ë ¨ ì´ë¯¸ì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "for i, question in enumerate(questions):\n",
    "    # ì§ˆë¬¸ì— ë³€ìˆ˜ë¥¼ ì‚½ì…í•©ë‹ˆë‹¤.\n",
    "    question = question.format(one=one, two=two, three=three, four=four)\n",
    "    \n",
    "    # ì§ˆë¬¸ì„ ì²´ì¸ì— ì „ë‹¬í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    print(f\"{i+1}ë²ˆì§¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "    response = chain.invoke(question)\n",
    "    res.append(response)\n",
    "\n",
    "print(\"âœ…ë‹µë³€ ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f7fa7eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì°¨15-1\n",
      "------------------------------------------------------\n",
      "ì‚¬ê±´ë¶„ë¥˜: ì°¨ëŒ€ì°¨  \n",
      "ì‚¬ê³ ì¥ì†Œ: ì§ì„  ë„ë¡œì—ì„œ ì£¼ì°¨êµ¬ì—­  \n",
      "ê°ì²´ A ìƒíƒœ: í›„í–‰ ì§ì§„  \n",
      "ê°ì²´ B ìƒíƒœ: ì£¼ì°¨êµ¬ì—­ì—ì„œ í›„ì§„ ì¶œì°¨  \n",
      "\n",
      "ì‚¬ê³  ìƒí™©: ì§ì„  ë„ë¡œì—ì„œ í›„í–‰ ì§ì§„ ì¤‘ì¸ A ì°¨ëŸ‰ê³¼ ì£¼ì°¨êµ¬ì—­ì—ì„œ í›„ì§„í•˜ì—¬ ì¶œì°¨í•˜ë ¤ëŠ” B ì°¨ëŸ‰ì´ ì¶©ëŒí•œ ì‚¬ê³ ì…ë‹ˆë‹¤.\n",
      "------------------------------------------------------\n",
      "A0:B100\n",
      "------------------------------------------------------\n",
      "- Bì°¨ëŸ‰ì´ ì£¼ì°¨êµ¬ì—­ì—ì„œ ì¶œì°¨í•˜ëŠ” ê³¼ì •ì—ì„œ ì°¨ì²´ë¥¼ í†µí–‰ë¡œì— ì¼ë¶€ ë…¸ì¶œì‹œí‚¤ê³  ëŒ€ê¸°í•˜ë‹¤ê°€ ì¶œì°¨í•˜ë˜ ì¤‘ì— ì‚¬ê³ ê°€ ë°œìƒí•œ ê²½ìš°, Bì°¨ëŸ‰ì˜ ì¶œì°¨ë¥¼ ì•Œ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê³¼ì‹¤ì„ 10% ê°ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "- Aì°¨ëŸ‰ì´ í†µë¡œì—ì„œ í›„ì§„í•˜ëŠ” ê²½ìš°ì—ëŠ” Bì°¨ëŸ‰ì´ í›„ì§„ì¶œì°¨í•˜ëŠ” ê²½ìš°ë³´ë‹¤ ì˜ˆì¸¡í•˜ê¸°ê°€ ìƒëŒ€ì ìœ¼ë¡œ ì–´ë ¤ìš°ë¯€ë¡œ, í›„ì§„ì˜ ì†ë„ë‚˜ ê±°ë¦¬ì— ë¹„ì¶”ì–´ Aì°¨ëŸ‰ì˜ ê³¼ì‹¤ì„ 10% ê°€ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "------------------------------------------------------\n",
      "ë„ë¡œêµí†µë²• ì œ5ì¡° (ì‹ í˜¸ ë˜ëŠ” ì§€ì‹œì— ë”°ë¥¼ ì˜ë¬´)\n",
      "------------------------------------------------------\n",
      "- ë²•ì›ëª…: ì„œìš¸ì¤‘ì•™ì§€ë°©ë²•ì›\n",
      "- ì„ ê³ ì¼: 2018.11.14.\n",
      "- ì‚¬ê±´ë²ˆí˜¸: 2018ë‹¤44045\n",
      "- í•µì‹¬ ë‚´ìš© ìš”ì•½: ì‹ í˜¸ë“±ì´ ì—†ê³  ëŒ€Â·ì†Œë¡œê°€ êµ¬ë³„ë˜ëŠ” êµì°¨ë¡œì—ì„œ ëŒ€ë¡œë¥¼ ì´ìš©í•œ Aì°¨ëŸ‰ê³¼ ì†Œë¡œë¥¼ ì´ìš©í•œ Bì°¨ëŸ‰ì´ ë™ì‹œì— êµì°¨ë¡œì— ì§„ì…í•˜ë‹¤ê°€ ë°œìƒí•œ ì‚¬ê³ \n",
      "- ê³¼ì‹¤ë¹„ìœ¨ ìš”ì•½: Bê³¼ì‹¤ 70%\n",
      "------------------------------------------------------\n",
      "[ì‚¬ê³  ìš”ì•½ :  \n",
      "ì‚¬ê³  ìœ í˜•: ì°¨ëŒ€ì°¨  \n",
      "ì¥ì†Œ: ì§ì„  ë„ë¡œ  \n",
      "ê°ì²´ A ìƒíƒœ: í›„í–‰ ì§ì§„  \n",
      "ê°ì²´ B ìƒíƒœ: ì£¼ì°¨êµ¬ì—­ì—ì„œ í›„ì§„ ì¶œì°¨]\n"
     ]
    }
   ],
   "source": [
    "acc_num = res[0].replace(\"ì‚¬ê³ ìœ í˜•ë²ˆí˜¸: \", \"\")\n",
    "acc_info = res[1].replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "basic_ratio = res[2][11:18]\n",
    "adjust_ratio = res[3].replace(\"ê³¼ì‹¤ ë¹„ìœ¨ ì¡°ì • ìš”ì†Œ:\\n\\n\", \"\").replace(\"]\", \"\")\n",
    "related_law = res[4].replace(\"[ê´€ë ¨ ë²•ë¥  : \", \"\").replace(\"]\", \"\")\n",
    "reference_case = res[5].replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "summary = res[6]\n",
    "\n",
    "print(acc_num, acc_info, basic_ratio, adjust_ratio, related_law, reference_case, summary, sep=\"\\n------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e8b056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1ë²ˆì§¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...\n",
      "2ë²ˆì§¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...\n",
      "3ë²ˆì§¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...\n",
      "âœ…ì£¼ìš” ìŸì  ë¶„ì„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "issue_prompt = PromptTemplate.from_template(\n",
    "    '''\n",
    "    ë‹¤ìŒì€ êµí†µì‚¬ê³  ë¶„ì„ ë³´ê³ ì„œì…ë‹ˆë‹¤.\n",
    "    ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¡œ ì‚¬ê³  ì •ë³´ë¥¼ ì •ë¦¬í•´ì£¼ì„¸ìš”.\n",
    "    ~~ ì…ë‹ˆë‹¤. ~~ ë‹µë³€ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ë“±ì˜ ë‹µë³€ì€ í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "    \n",
    "    ì£¼ìš” ìŸì ì— ëŒ€í•´ ì§ˆë¬¸í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "    [ì£¼ìš” ìŸì  : ì‚¬ê³ ì—ì„œ í•µì‹¬ì ìœ¼ë¡œ íŒë‹¨í•´ì•¼ í•  í¬ì¸íŠ¸ì™€ ê³¼ì‹¤ë¹„ìœ¨ ì‚°ì •ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆëŠ” ì£¼ìš” ìŸì ì„ ì„œìˆ í•´ ì£¼ì„¸ìš”.]\n",
    "    \n",
    "    ê²°ì • ê·¼ê±°ì— ëŒ€í•´ ì§ˆë¬¸í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "    [ê²°ì • ê·¼ê±° : ì‚¬ê³ ì˜ íŒë‹¨ì— ì˜í–¥ì„ ë¯¸ì¹œ ìš”ì†Œë“¤ê³¼ íŒë‹¨ ê·¼ê±°, íŒë‹¨ì˜ ì£¼ìš” ë…¼ë¦¬ë¥¼ ì„œìˆ í•´ ì£¼ì„¸ìš”.]\n",
    "    \n",
    "    ë²•ë¥  í‚¤ì›Œë“œì— ëŒ€í•´ ì§ˆë¬¸í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "    [ë²•ë¥  í‚¤ì›Œë“œ : ì‚¬ê³ ì˜ ë²•ë¥ ì  í•´ì„ ë° íŒë‹¨ì— ì¤‘ìš”í•œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ 3~5ê°œ ì¶”ì¶œí•´ ì£¼ì„¸ìš”. ì˜ˆ: ì„ ì§„ì… ìš°ì„ , ì§„ë¡œë³€ê²½, êµì°¨ë¡œ í†µí–‰ ìš°ì„ , ì‹ í˜¸ìœ„ë°˜, ìš°ì¸¡ì°¨ ìš°ì„  ë“±]\n",
    "\n",
    "    ë¶„ì„ ìš”ì•½:\n",
    "    {analysis}\n",
    "    '''\n",
    ")\n",
    "\n",
    "issue_chain = (\n",
    "    {\"analysis\": RunnablePassthrough()}\n",
    "    | issue_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "questions = [summary + \"ì˜ ì£¼ìš” ìŸì ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "            summary + \"ì˜ ê²°ì • ê·¼ê±°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "            summary + \"ì˜ ë²•ë¥  í‚¤ì›Œë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"]\n",
    "\n",
    "summary_res = []\n",
    "for i, question in enumerate(questions):\n",
    "    # ì§ˆë¬¸ì— ë³€ìˆ˜ë¥¼ ì‚½ì…í•©ë‹ˆë‹¤.\n",
    "    question = question.format(summary=summary)\n",
    "    \n",
    "    # ì§ˆë¬¸ì„ ì²´ì¸ì— ì „ë‹¬í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    print(f\"{i+1}ë²ˆì§¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "    response = issue_chain.invoke(question)\n",
    "    summary_res.append(response)\n",
    "\n",
    "print(\"âœ…ì£¼ìš” ìŸì  ë¶„ì„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "875680a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¬ê³ ì—ì„œ í•µì‹¬ì ìœ¼ë¡œ íŒë‹¨í•´ì•¼ í•  í¬ì¸íŠ¸ì™€ ê³¼ì‹¤ë¹„ìœ¨ ì‚°ì •ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆëŠ” ì£¼ìš” ìŸì ì€ í›„í–‰ ì§ì§„ ì¤‘ì¸ ê°ì²´ Aì™€ ì£¼ì°¨êµ¬ì—­ì—ì„œ í›„ì§„ ì¶œì°¨ ì¤‘ì¸ ê°ì²´ B ê°„ì˜ ì¶©ëŒ ìƒí™©ì…ë‹ˆë‹¤. íŠ¹íˆ, ê°ì²´ Bê°€ ì£¼ì°¨êµ¬ì—­ì—ì„œ ë„ë¡œë¡œ ì§„ì…í•  ë•Œì˜ ì£¼ì˜ ì˜ë¬´ì™€ ê°ì²´ Aì˜ ì£¼í–‰ ì†ë„ ë° ì£¼ì˜ ì˜ë¬´ê°€ ì£¼ìš” ìŸì ì´ ë©ë‹ˆë‹¤. ê°ì²´ Bì˜ í›„ì§„ ì¶œì°¨ ì‹œ ë„ë¡œ ìƒí™©ì„ ì¶©ë¶„íˆ ì‚´í”¼ê³  ì•ˆì „í•˜ê²Œ ì§„ì…í–ˆëŠ”ì§€ ì—¬ë¶€ì™€ ê°ì²´ Aê°€ ì´ë¥¼ ì¸ì§€í•˜ê³  ì ì ˆí•œ ëŒ€ì‘ì„ í–ˆëŠ”ì§€ê°€ ê³¼ì‹¤ë¹„ìœ¨ ì‚°ì •ì— ì¤‘ìš”í•œ ìš”ì†Œë¡œ ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì‚¬ê³ ì˜ íŒë‹¨ì— ì˜í–¥ì„ ë¯¸ì¹œ ìš”ì†Œë“¤ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ì²«ì§¸, ê°ì²´ AëŠ” ì§ì„  ë„ë¡œì—ì„œ ì •ìƒì ìœ¼ë¡œ í›„í–‰ ì§ì§„ ì¤‘ì´ì—ˆìœ¼ë©°, ë„ë¡œì˜ íë¦„ì„ ë°©í•´í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‘˜ì§¸, ê°ì²´ BëŠ” ì£¼ì°¨êµ¬ì—­ì—ì„œ í›„ì§„í•˜ì—¬ ì¶œì°¨í•˜ëŠ” ìƒí™©ì´ì—ˆìœ¼ë©°, ì´ ê³¼ì •ì—ì„œ ë„ë¡œë¡œ ì§„ì…í•˜ê¸° ì „ì— í›„ë°© ë° ì¸¡ë©´ì˜ ì•ˆì „ì„ ì¶©ë¶„íˆ í™•ì¸í•˜ì§€ ì•Šì•˜ì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ìƒí™©ì—ì„œ í›„ì§„ ì¶œì°¨í•˜ëŠ” ì°¨ëŸ‰ì€ ë„ë¡œë¥¼ ì£¼í–‰ ì¤‘ì¸ ì°¨ëŸ‰ì— ëŒ€í•´ ì£¼ì˜ ì˜ë¬´ê°€ ìˆìœ¼ë©°, ì•ˆì „í•˜ê²Œ ì§„ì…í•  ì±…ì„ì´ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ê°ì²´ Bì˜ ì£¼ì˜ ì˜ë¬´ ì†Œí™€ ë° ì•ˆì „ í™•ì¸ ë¶€ì¡±ì´ ì‚¬ê³ ì˜ ì£¼ìš” ì›ì¸ìœ¼ë¡œ íŒë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "['í›„ì§„ ì¶œì°¨', 'ì§ì§„ ìš°ì„ ', 'ì£¼ì°¨êµ¬ì—­', 'í›„í–‰ ì§ì§„', 'ë„ë¡œ í†µí–‰']\n"
     ]
    }
   ],
   "source": [
    "main_issue = summary_res[0].replace(\"[ì£¼ìš” ìŸì  : \", \"\").replace(\"]\", \"\")\n",
    "decision_basis = summary_res[1].replace(\"[ê²°ì • ê·¼ê±° : \", \"\").replace(\"]\", \"\")\n",
    "law_keywords = summary_res[2].replace(\"[ë²•ë¥  í‚¤ì›Œë“œ : \", \"\").replace(\"]\", \"\").split(\", \")\n",
    "\n",
    "print(main_issue, decision_basis, law_keywords, sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3c981ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ë„ë¡œêµí†µë²• PDF ê¸°ë°˜ ë²•ë ¹ ë²¡í„° ì €ì¥ì†Œ êµ¬ì„±\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# PDF ê²½ë¡œ\n",
    "traffic_law_pdf_path = work_dir + \"LangChain/pdf_data/ë„ë¡œêµí†µë²•.pdf\"\n",
    "\n",
    "# 1. ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• \n",
    "traffic_loader = PyPDFLoader(traffic_law_pdf_path)\n",
    "traffic_docs = traffic_loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "traffic_chunks = splitter.split_documents(traffic_docs)\n",
    "\n",
    "# 2. ë²¡í„°í™” ë° retriever ìƒì„±\n",
    "embedding = OpenAIEmbeddings()\n",
    "traffic_vectorstore = FAISS.from_documents(traffic_chunks, embedding)\n",
    "traffic_retriever = traffic_vectorstore.as_retriever()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "\n",
    "law_prompt = PromptTemplate.from_template(\n",
    "    '''\n",
    "    ë‹¤ìŒì€ êµí†µì‚¬ê³  ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤. ê´€ë ¨ ë„ë¡œêµí†µë²• ì¡°í•­ì„ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ 2~3ê°œ ì„ ì •í•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”.\n",
    "\n",
    "    ì‚¬ê³ :\n",
    "    {question}\n",
    "\n",
    "    [ì°¸ê³  ë¬¸ì„œ]\n",
    "    --------------------\n",
    "    {law_context}\n",
    "    --------------------\n",
    "\n",
    "    ğŸ”¹ ê° ì¡°í•­ì€ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”:\n",
    "    ì œ13ì¡° ì œ1í•­:\n",
    "    \"ëª¨ë“  ì°¨ì˜ ìš´ì „ìëŠ” ...\"\n",
    "    â  ... ìƒí™©ì— ì ìš©ë˜ë©°, ì´ ì‚¬ê±´ì—ì„œëŠ” ... ì´ìœ ë¡œ íŒë‹¨ë¨.\n",
    "\n",
    "    âœ³ï¸ ìœ ì‚¬ ì ìš© ê°€ëŠ¥í•œ ì¡°í•­ì´ ìˆë‹¤ë©´ ì¶”ê°€ë¡œ ê°„ë‹¨íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\n",
    "    '''\n",
    ")\n",
    "\n",
    "related_law_chain = (\n",
    "    {\"law_context\": traffic_retriever, \"question\": RunnablePassthrough()}\n",
    "    | law_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "traffic_response = related_law_chain.invoke(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d5a0955a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì œ16ì¡° ì œ1í•­:\\n\"ìë™ì°¨ë“±ì˜ ìš´ì „ìëŠ” ì•ì°¨ì™€ì˜ ì¶©ëŒì„ í”¼í•  ìˆ˜ ìˆëŠ” í•„ìš”í•œ ê±°ë¦¬ë¥¼ í™•ë³´í•˜ì—¬ì•¼ í•œë‹¤.\"\\nâ ì´ ì¡°í•­ì€ í›„í–‰ ì°¨ëŸ‰ì´ ì•ì°¨ì™€ì˜ ì•ˆì „í•œ ê±°ë¦¬ë¥¼ ìœ ì§€í•´ì•¼ í•¨ì„ ê·œì •í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ì‚¬ê±´ì—ì„œëŠ” ê°ì²´ Aê°€ í›„í–‰ ì§ì§„ ì¤‘ì´ì—ˆìœ¼ë¯€ë¡œ, ê°ì²´ Bê°€ ì£¼ì°¨êµ¬ì—­ì—ì„œ í›„ì§„ ì¶œì°¨í•˜ëŠ” ìƒí™©ì—ì„œë„ ì¶©ëŒì„ í”¼í•  ìˆ˜ ìˆëŠ” ê±°ë¦¬ë¥¼ í™•ë³´í•´ì•¼ í–ˆìŠµë‹ˆë‹¤.\\n\\nì œ32ì¡°:\\n\"ëª¨ë“  ì°¨ì˜ ìš´ì „ìëŠ” ë‹¤ìŒ ê° í˜¸ì˜ ì–´ëŠ í•˜ë‚˜ì— í•´ë‹¹í•˜ëŠ” ê³³ì—ì„œëŠ” ì°¨ë¥¼ ì •ì°¨í•˜ê±°ë‚˜ ì£¼ì°¨í•˜ì—¬ì„œëŠ” ì•„ë‹ˆ ëœë‹¤.\"\\nâ ì´ ì¡°í•­ì€ ì£¼ì°¨ê°€ ê¸ˆì§€ëœ ì¥ì†Œì—ì„œì˜ ì£¼ì°¨ë¥¼ ê·œì •í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ì‚¬ê±´ì—ì„œëŠ” ê°ì²´ Bê°€ ì£¼ì°¨êµ¬ì—­ì—ì„œ í›„ì§„ ì¶œì°¨í•˜ì˜€ìœ¼ë¯€ë¡œ, í•´ë‹¹ ì£¼ì°¨êµ¬ì—­ì´ ë„ë¡œêµí†µë²•ì— ë”°ë¥¸ ì£¼ì°¨ ê¸ˆì§€ êµ¬ì—­ì¸ì§€ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤. ë§Œì•½ ì£¼ì°¨ ê¸ˆì§€ êµ¬ì—­ì—ì„œ ì£¼ì°¨í•˜ì˜€ë‹¤ë©´, ì´ ì¡°í•­ì— ìœ„ë°˜ëœ ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "97670403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: C:/Users/Noh/github/Accident_Prediction_Prevent/Models/work_dir//datasets/results/bb_1_220122_vehicle_229_34825.pdf\n"
     ]
    }
   ],
   "source": [
    "### ë³´ê³ ì„œ ìƒì„±\n",
    "def create_report_pdf(response, summary, traffic_response, output_filename=None):\n",
    "    # ì¶œë ¥ ë””ë ‰í† ë¦¬\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    res = response\n",
    "    summary_res = summary\n",
    "    traffic_response = traffic_response\n",
    "    \n",
    "    # íŒŒì¼ëª… ìƒì„± (ì§€ì •ë˜ì§€ ì•Šì€ ê²½ìš° íƒ€ì„ìŠ¤íƒ¬í”„ ì‚¬ìš©)\n",
    "    if not output_filename:\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_filename = f\"accident_report_{timestamp}.pdf\"\n",
    "    \n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    \n",
    "    # PDF ë¬¸ì„œ ì„¤ì •\n",
    "    doc = SimpleDocTemplate(output_path, pagesize=letter, \n",
    "                           rightMargin=72, leftMargin=72,\n",
    "                           topMargin=72, bottomMargin=72)\n",
    "    \n",
    "    # ìŠ¤íƒ€ì¼ ì„¤ì • - ê¸°ì¡´ ìŠ¤íƒ€ì¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    styles = getSampleStyleSheet()\n",
    "    \n",
    "    # ëŒ€ì œëª© ìŠ¤íƒ€ì¼ ìˆ˜ì • (í•œê¸€ í°íŠ¸ ì ìš©)\n",
    "    styles['Title'].fontName = 'MalgunBold'\n",
    "    styles['Title'].alignment = 1  # ê°€ìš´ë° ì •ë ¬\n",
    "    styles['Title'].fontSize = 16\n",
    "    styles['Title'].spaceAfter = 12\n",
    "\n",
    "    # ì¤‘ì œëª©\n",
    "    styles['Heading1'].fontName = 'MalgunBold'\n",
    "    styles['Heading1'].fontSize = 14\n",
    "    \n",
    "    # Normal ìŠ¤íƒ€ì¼ë„ í•œê¸€ í°íŠ¸ë¡œ ìˆ˜ì •\n",
    "    styles['Normal'].fontName = 'Malgun'\n",
    "    styles['Normal'].fontSize = 11\n",
    "\n",
    "    # ìƒˆ ìŠ¤íƒ€ì¼ ì¶”ê°€ (í•œê¸€ í°íŠ¸ ì ìš©)\n",
    "    styles.add(ParagraphStyle(name='DateStyle',\n",
    "                              fontName='MalgunBold',\n",
    "                              fontSize=11,\n",
    "                              alignment=2))  # ì˜¤ë¥¸ìª½ ì •ë ¬\n",
    "    \n",
    "    styles.add(ParagraphStyle(name='img_name',\n",
    "                              fontName='Malgun',\n",
    "                              fontSize=9,\n",
    "                              alignment=1))  # ê°€ìš´ë° ì •ë ¬\n",
    "    \n",
    "    styles.add(ParagraphStyle(name='acc_ratio',\n",
    "                              fontName='MalgunBold',\n",
    "                              fontSize=20,\n",
    "                              alignment=1))  # ê°€ìš´ë° ì •ë ¬\n",
    "    \n",
    "    # ë¬¸ì„œ ë‚´ìš©\n",
    "    elements = []\n",
    "    \n",
    "    # ì œëª©\n",
    "    title = Paragraph(\"ì‚¬ê³  ë¶„ì„ ë³´ê³ ì„œ\", styles['Title'])\n",
    "    elements.append(title)\n",
    "    elements.append(Spacer(1, 0.25*inch))\n",
    "    \n",
    "    # ë‚ ì§œ ì¶”ê°€\n",
    "    date_str = datetime.datetime.now().strftime(\"%Yë…„ %mì›” %dì¼\")\n",
    "    date_paragraph = Paragraph(f\"ì‘ì„±ì¼: {date_str}\", styles['DateStyle'])\n",
    "    elements.append(date_paragraph)\n",
    "    elements.append(Spacer(1, 0.25*inch))\n",
    "\n",
    "    # ê¸°ë³¸ ì •ë³´ ì…ë ¥ë€\n",
    "    basic_info_title = Paragraph(\"[ì‚¬ê³  ë°œìƒ ì •ë³´]\", styles['Heading1'])\n",
    "    elements.append(basic_info_title)\n",
    "    basic_info = Paragraph(\"ì‚¬ê³  ë°œìƒì¼ : <br/> ì‚¬ê³  ì§€ì  : \", styles['Normal'])\n",
    "    elements.append(basic_info)\n",
    "    elements.append(Spacer(1, 0.5*inch))\n",
    "    \n",
    "    # ë‹µë³€ ì„¹ì…˜\n",
    "    acc_num = res[0].replace(\"ì‚¬ê³ ìœ í˜•ë²ˆí˜¸: \", \"\")\n",
    "    acc_info = res[1].replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    basic_ratio = res[2][11:18]\n",
    "    adjust_ratio = res[3].replace(\"ê³¼ì‹¤ ë¹„ìœ¨ ì¡°ì • ìš”ì†Œ:\\n\\n\", \"\").replace(\"]\", \"\")\n",
    "    related_law = res[4].replace(\"[ê´€ë ¨ ë²•ë¥  : \", \"\").replace(\"]\", \"\")\n",
    "    reference_case = res[5].replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    main_issue = summary_res[0].replace(\"[ì£¼ìš” ìŸì  : \", \"\").replace(\"]\", \"\")\n",
    "    decision_basis = summary_res[1].replace(\"[ê²°ì • ê·¼ê±° : \", \"\").replace(\"]\", \"\")\n",
    "    law_keywords = summary_res[2].replace(\"[ë²•ë¥  í‚¤ì›Œë“œ : \", \"\").replace(\"]\", \"\").split(\", \")\n",
    "    traffic_response = traffic_response\n",
    "\n",
    "    # ì¤„ë°”ê¿ˆì„ HTML <br/>ë¡œ ëŒ€ì²´\n",
    "    acc_num_p = Paragraph(\"<\" + acc_num + \">\", styles['img_name'])\n",
    "    acc_info = Paragraph(acc_info.replace('\\n', '<br/>'), styles['Normal'])\n",
    "    basic_ratio = Paragraph(basic_ratio, styles['acc_ratio'])\n",
    "    adjust_ratio = Paragraph(adjust_ratio.replace('\\n', '<br/>'), styles['Normal'])\n",
    "    related_law = Paragraph(related_law, styles['Normal'])\n",
    "    reference_case = Paragraph(reference_case.replace('\\n', '<br/>'), styles['Normal'])\n",
    "    main_issue = Paragraph(main_issue, styles['Normal'])\n",
    "    decision_basis = Paragraph(decision_basis, styles['Normal'])\n",
    "\n",
    "    traffic_response = Paragraph(traffic_response.replace('\\n', '<br/>'), styles['Normal'])\n",
    "\n",
    "    # AI ë¶„ì„ ì‚¬ê³  ì •ë³´ ë° ìƒí™©\n",
    "    acc_info_title = Paragraph(\"[AI ë¶„ì„ ì‚¬ê³  ì •ë³´ ë° ìƒí™©]\", styles['Heading1'])\n",
    "    elements.append(acc_info_title)\n",
    "    elements.append(acc_info)\n",
    "    elements.append(Spacer(1, 0.25*inch))\n",
    "\n",
    "    # ì‚¬ê³ ìœ í˜•ì— ë§ëŠ” ì´ë¯¸ì§€ ì²¨ë¶€\n",
    "    img_dir = os.path.join(work_dir, \"LangChain/pdf_images/\")\n",
    "    image = os.path.join(img_dir, f\"{acc_num}.jpeg\")\n",
    "    if os.path.exists(image):\n",
    "        img = Image.open(image)\n",
    "        img = img.convert(\"RGB\")\n",
    "        img_stream = BytesIO()\n",
    "        img.save(img_stream, format=\"JPEG\")\n",
    "        img_stream.seek(0)\n",
    "        \n",
    "        # ì´ë¯¸ì§€ ì¶”ê°€\n",
    "        report_image = ReportImage(img_stream, width=6*inch, height=4*inch)\n",
    "        # report_image = ReportImage(img_stream, width=doc.width, height=doc.width * 0.75)\n",
    "        elements.append(report_image)\n",
    "        elements.append(Spacer(1, 0.25*inch))\n",
    "    else:\n",
    "        print(f\"âŒ ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {image}\")\n",
    "\n",
    "    elements.append(acc_num_p)\n",
    "    elements.append(Spacer(1, 0.25*inch))\n",
    "\n",
    "    # âœ… ë‹¤ìŒ í˜ì´ì§€ë¡œ ê°•ì œ ì´ë™\n",
    "    elements.append(PageBreak())    \n",
    "\n",
    "    # AI ë¶„ì„ ê¸°ë³¸ ê³¼ì‹¤ ë¹„ìœ¨\n",
    "    basic_ratio_title = Paragraph(\"[AI ë¶„ì„ ê¸°ë³¸ ê³¼ì‹¤ ë¹„ìœ¨]\", styles['Heading1'])\n",
    "    elements.append(basic_ratio_title)\n",
    "    elements.append(basic_ratio)\n",
    "    elements.append(Spacer(1, 0.5*inch))\n",
    "\n",
    "    # ê³¼ì‹¤ë¹„ìœ¨ ì¡°ì • ìš”ì†Œ\n",
    "    adjust_ratio_title = Paragraph(\"[AI ë¶„ì„ ê³¼ì‹¤ë¹„ìœ¨ ì¡°ì • ìš”ì†Œ]\", styles['Heading1'])\n",
    "    elements.append(adjust_ratio_title)\n",
    "    elements.append(adjust_ratio)\n",
    "    elements.append(Spacer(1, 0.5*inch))\n",
    "\n",
    "    # ê´€ë ¨ ë²•ë¥ \n",
    "    related_law_title = Paragraph(\"[AI ë¶„ì„ ê´€ë ¨ ë²•ë¥ ]\", styles['Heading1'])\n",
    "    elements.append(related_law_title)\n",
    "    elements.append(related_law)\n",
    "    elements.append(Spacer(1, 0.5*inch))\n",
    "\n",
    "    # ì°¸ê³  íŒë¡€\n",
    "    reference_case_title = Paragraph(\"[AI ë¶„ì„ ì°¸ê³  íŒë¡€]\", styles['Heading1'])\n",
    "    elements.append(reference_case_title)\n",
    "    elements.append(reference_case)\n",
    "    elements.append(Spacer(1, 0.5*inch))\n",
    "\n",
    "    # ì£¼ìš” ìŸì \n",
    "    main_issue_title = Paragraph(\"[AI ë¶„ì„ ì£¼ìš” ìŸì ]\", styles['Heading1'])\n",
    "    elements.append(main_issue_title)\n",
    "    elements.append(main_issue)\n",
    "    elements.append(Spacer(1, 0.5*inch))\n",
    "\n",
    "    # ê²°ì • ê·¼ê±°\n",
    "    decision_basis_title = Paragraph(\"[AI ë¶„ì„ ê²°ì • ê·¼ê±°]\", styles['Heading1'])\n",
    "    elements.append(decision_basis_title)\n",
    "    elements.append(decision_basis)\n",
    "    elements.append(Spacer(1, 0.5*inch))\n",
    "\n",
    "    # ë²•ë¥  í‚¤ì›Œë“œ\n",
    "\n",
    "    # ë„ë¡œêµí†µë²•\n",
    "    traffic_response_title = Paragraph(\"[ë„ë¡œêµí†µë²• ê´€ë ¨ ì¡°í•­]\", styles['Heading1'])\n",
    "    elements.append(traffic_response_title)\n",
    "    elements.append(traffic_response)\n",
    "    elements.append(Spacer(1, 0.25*inch))\n",
    "    \n",
    "    # PDF ìƒì„±\n",
    "    doc.build(elements)\n",
    "    print(f\"âœ… ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# ë³´ê³ ì„œ ìƒì„±\n",
    "def generate_accident_report(pdf_path, response):\n",
    "    pdf_path = pdf_path\n",
    "    response = response\n",
    "\n",
    "    report_title = f\"{video_name}.pdf\"\n",
    "    \n",
    "    # PDF ë³´ê³ ì„œ ìƒì„±\n",
    "    pdf_path = create_report_pdf(\n",
    "        response=response,\n",
    "        summary=summary_res,\n",
    "        traffic_response=traffic_response,\n",
    "        output_filename=report_title\n",
    "    )\n",
    "    \n",
    "    return pdf_path\n",
    "\n",
    "# ë³´ê³ ì„œ ìƒì„± ì‹¤í–‰\n",
    "report_file = generate_accident_report(pdf_path, res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lang_Chain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
